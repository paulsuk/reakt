"# reakt" 

For enlight's HACKference:

ReaKt conducts real-time facial sentiment analysis on audiences, leveraging computer vision and a state of the art machine learning algorithm. Through the use of Google's Cloud Vision API, ReaKt is able to gather and visualize data corresponding to the audiences' reactions during a presentation, meeting, conference, etc.

ReaKt outputs a video of the speaker or presenter's presentation with a line graph of the audiences' emotions over time, and pi graph of the audiences' emotions at that moment. By providing the audiences' feedback overlayed on the presentation, the presenter is able to reflect on their delivery, impact, and ability to reach their audience.

For demo and proof-of-concept purposes, the following output video includes a video stream of the audience, as opposed to the presenter, to illustrate that the graphs represent the emotions of the 4 individuals on screen. Check it out below!

https://www.youtube.com/watch?v=9INa5sZB5GY

Video to be analyzed is required to be in the same folder as FacialReq.py and titled 'video.mp4'

Made by:
Paul Suk, Grace Kumagai, Connor Lawless, Zaid Kassar, Quinten Coetsee